<html>
<head>
    <title>audio recorder test</title>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
    <style>
        li { list-style: none; }
    </style>
</head>
<body>
     <div class="container text-center">
        <h1>Mic Recorder Example</h1>
        <hr />

        <button class="btn btn-primary">Start recording</button>

        <br />
        <br />
        <br />

        <ul id="playlist"></ul>
        <p id="duration"></p>
    </div>

    <script>
        const button = document.querySelector('button');
        const options = {mimeType: 'audio/webm'};
        const buffer = [];
        var mediaRecorder = null;
        var startTime = null;
        var endTime = null;
        var lastDetectedTime = null;
        const VOICE_MIN_DECIBELS      = -35;
        var duration = 0;
        var total = 0;
        var soundDetected = false;
        var DELAY_BETWEEN_DIALOGS   = 3000; // set 3 sec delay as benchmark

        // start the recording
        const startRecording = function() {
            mediaRecorder.start();
            button.textContent = 'Mute';
            button.classList.toggle('btn-danger');
            button.removeEventListener('click', startRecording);
            button.addEventListener('click', stopRecording);
        }

        // stop the recording
        const stopRecording = function() {
            mediaRecorder.stop();
            button.textContent = 'Unmute';
            button.classList.toggle('btn-danger');
            button.removeEventListener('click', stopRecording);
            button.addEventListener('click', startRecording);
        }

        // init the audio system
        const handleInit = function(stream) {
            // start recording with a click of the button
            button.addEventListener('click', startRecording);

            // mediaRecorder object that captures the stream
            mediaRecorder = new MediaRecorder(stream, options);

            // Record the timestamp (start of recording) when MediaRecorder's start event is triggered
            mediaRecorder.addEventListener('start', () => {
                startTime = new Date().valueOf();
                //window.requestAnimationFrame(detectSound);
            });

            // catches stream of bytearray
            mediaRecorder.addEventListener('dataavailable', function(e) {
                if (e.data.size > 0) buffer.push(e.data);
            });

            // when stopped, create a file and allow playback
            mediaRecorder.addEventListener('stop', function() {
                console.dir(buffer);

               // if(!soundDetected) return;

                // Record the timestamp (end of recording) when MediaRecorder's stop event is triggered
                endTime = new Date().getTime();

                //create a file from the stream buffer
                const file = new File(buffer, 'audio.webm', {
                    type: 'audio/webm',
                    lastModified: Date.now()
                });          

                // calculate duration of the recording in seconds
                //duration = duration + (endTime - lastDetectedTime)/1000;
                if(lastDetectedTime - startTime <= DELAY_BETWEEN_DIALOGS){
                   lastDetectedTime = startTime; // last detected time isn't too different from start time
               }
                if(soundDetected){
                    duration = (endTime - lastDetectedTime); //there was an ongoing dialog. 
                }
                
                total += duration;
                document.getElementById("duration").innerHTML = total/1000;

                // display the file via an Audio object
                const li = document.createElement('li');
                const player = new Audio(URL.createObjectURL(file));
                player.controls = true;
                li.appendChild(player);
                document.querySelector('#playlist').appendChild(li);
                buffer.length = 0; // empty the buffer for the next one
                duration = 0; // reset recording duration 
                soundDetected = false; // reset sound detection
            });   
            
            const audioContext = new AudioContext();
            const audioStreamSource = audioContext.createMediaStreamSource(stream);
            const analyser = audioContext.createAnalyser();
            analyser.minDecibels = VOICE_MIN_DECIBELS;
            audioStreamSource.connect(analyser);

            const bufferLength = analyser.frequencyBinCount;
            const domainData = new Uint8Array(bufferLength);

            soundDetected = false;
            const detectSound = function() {
                //if (soundDetected) {
                //    return
                //}
               time = new Date(); 
               currentTime = time.getTime();

               if(lastDetectedTime - startTime <= DELAY_BETWEEN_DIALOGS){
                   lastDetectedTime = startTime; // last detected time isn't too different from start time
               }

                //a dialog detected:
                if(soundDetected)
                {                    
                    duration = (currentTime - lastDetectedTime); //ongoing dialog, overwrite.                    
                }
            
                analyser.getByteFrequencyData(domainData); 

                var foundSound = false;
                for (let i = 0; i < bufferLength; i++) {
                    const value = domainData[i];

                    if (domainData[i] > 0) { // detect a spike
                        time = new Date(); 
                        if(!soundDetected) { // transition to sound detected
                            lastDetectedTime = time.getTime(); // move to current
                        }
                        soundDetected = true;
                        console.log("Sound detected")
                        foundSound = true;                                               
                    }                                      
                }
                if(!foundSound){  // did not find any sound in this chunk which means dialog ended
                    soundDetected = false;
                    console.log("Sound Not detected")
                    total += duration;
                    duration = 0; // reset dialog length
                }
                console.log(total)
                window.requestAnimationFrame(detectSound); // loop
            };
            window.requestAnimationFrame(detectSound); // start loop
        };

        // init the stream from the audio device
        navigator.mediaDevices.getUserMedia({ audio: true, video: false })
            .then(handleInit);

    </script>
</body>
</html>
